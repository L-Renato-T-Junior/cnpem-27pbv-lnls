{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preambulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#para graficos interativos\n",
    "#%matplotlib notebook\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "#para imagens estaticas embebidas\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dtm\n",
    "import re\n",
    "import scipy as spy\n",
    "import glob\n",
    "import csv\n",
    "\n",
    "from matplotlib import ticker, cm\n",
    "from scipy import integrate\n",
    "from scipy.special import sph_harm\n",
    "from scipy import interpolate\n",
    "from numpy import array, linspace, arange, zeros, ceil, amax, amin, argmax, argmin, abs, average\n",
    "from numpy import polyfit, polyval, seterr, trunc, mean\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Background LINEAR ####################\n",
    "\n",
    "DEBUG = False\n",
    "\n",
    "def linearBG(x, y):\n",
    "    \"\"\" P = specs.preedge_calculate(x,y)\n",
    "    Calculates the best-fit linear pre-edge for a dataset (x,y). Finds the biggest peak,\n",
    "    then finds the pre-edge region using a sequence of linear fits starting from the end\n",
    "    point.\n",
    "    \"\"\"\n",
    "\n",
    "    # Make sure we've been passed arrays and not lists.\n",
    "    x = array(x)\n",
    "    y = array(y)\n",
    "\n",
    "    # Sanity check: Do we actually have data to process here?\n",
    "    if not (x.any() and y.any()):\n",
    "        print('specs.preedge_calculate: One of the arrays x or y is empty. Returning zero background.')\n",
    "        return zeros(x.shape)\n",
    "\n",
    "    # Next ensure the energy values are *decreasing* in the array,\n",
    "    # if not, reverse them.\n",
    "    if x[0] < x[-1]:\n",
    "        is_reversed = True\n",
    "        x = x[::-1]\n",
    "        y = y[::-1]\n",
    "    else:\n",
    "        is_reversed = False\n",
    "\n",
    "    # Locate the biggest peak.\n",
    "    maxidx = abs(y - amax(y)).argmin()\n",
    "\n",
    "    # Find the gradient of every possible linear fit between the lowest binding energy\n",
    "    # and the biggest peak.\n",
    "    grads = []\n",
    "    for i in range(2, len(x) - maxidx):\n",
    "        # Best linear fit to the last i values\n",
    "        xs = x[-i:]\n",
    "        ys = y[-i:]\n",
    "        #p = polyfit(xs,ys,1)\n",
    "        #grads.append(p[0])\n",
    "        # Try a new algorithm that should be faster than polyfit\n",
    "        xs = xs - mean(xs)\n",
    "        ys = ys - mean(ys)\n",
    "        grads.append((xs * ys).sum() / (xs * xs).sum())\n",
    "\n",
    "    # Differentiate the gradient array.\n",
    "    dgrads = []\n",
    "    for i in range(len(grads) - 1):\n",
    "        dgrads.append(grads[i + 1] - grads[i])\n",
    "    dgrads = array(dgrads)\n",
    "\n",
    "    # We might not have actually accumulated anything if the maximum is near the\n",
    "    # edge (like in a survey scan - the SE background is very big). So, may have\n",
    "    # to return a zero background.\n",
    "    if not dgrads.any():\n",
    "        print('specs.preedge_calculate: No pre-edge gradients. The spectrum must be very large at the low kinetic energy end. Returning zero background.')\n",
    "        return zeros(x.shape)\n",
    "\n",
    "    # Find the minimum index of the absolute of the gradient of gradients.\n",
    "    mingrad = abs(dgrads).argmin()\n",
    "\n",
    "    # Make a best linear fit from this number of pre-edge points, generate linear\n",
    "    # pre-edge.\n",
    "    p = polyfit(x[-mingrad:], y[-mingrad:], 1)\n",
    "\n",
    "    if is_reversed:\n",
    "        return polyval(p, x)[::-1]\n",
    "    else:\n",
    "        return polyval(p, x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Background SHIRLEY ####################\n",
    "\n",
    "def shirley(x, y, tol=1e-5, maxit=10):\n",
    "    \"\"\" S = specs.shirley_calculate(x,y, tol=1e-5, maxit=10)\n",
    "    Calculate the best auto-Shirley background S for a dataset (x,y). Finds the biggest peak\n",
    "    and then uses the minimum value either side of this peak as the terminal points of the\n",
    "    Shirley background.\n",
    "    The tolerance sets the convergence criterion, maxit sets the maximum number\n",
    "    of iterations.\n",
    "    \"\"\"\n",
    "\n",
    "    # Make sure we've been passed arrays and not lists.\n",
    "    x = array(x)\n",
    "    y = array(y)\n",
    "\n",
    "    # Sanity check: Do we actually have data to process here?\n",
    "    if not (x.any() and y.any()):\n",
    "        print (\"specs.shirley_calculate: One of the arrays x or y is empty. Returning zero background.\")\n",
    "        return zeros(x.shape)\n",
    "\n",
    "    # Next ensure the energy values are *decreasing* in the array,\n",
    "    # if not, reverse them.\n",
    "    if x[0] < x[-1]:\n",
    "        is_reversed = True\n",
    "        x = x[::-1]\n",
    "        y = y[::-1]\n",
    "    else:\n",
    "        is_reversed = False\n",
    "\n",
    "    # Locate the biggest peak.\n",
    "    maxidx = abs(y - amax(y)).argmin()\n",
    "    #print('valor:',maxidx)\n",
    "\n",
    "    # It's possible that maxidx will be 0 or -1. If that is the case,\n",
    "    # we can't use this algorithm, we return a zero background.\n",
    "    if maxidx == 0 or maxidx >= len(y) - 1:\n",
    "        print(\"specs.shirley_calculate: Boundaries too high for algorithm: returning a zero background.\")\n",
    "        return zeros(x.shape)\n",
    "\n",
    "    # Locate the minima either side of maxidx.\n",
    "    lmidx = abs(y[0:maxidx] - amin(y[0:maxidx])).argmin()\n",
    "    rmidx = abs(y[maxidx:] - amin(y[maxidx:])).argmin() + maxidx\n",
    "    xl = x[lmidx]\n",
    "    yl = y[lmidx]\n",
    "    xr = x[rmidx]\n",
    "    yr = y[rmidx]\n",
    "\n",
    "    # Max integration index\n",
    "    imax = rmidx - 1\n",
    "\n",
    "    # Initial value of the background shape B. The total background S = yr + B,\n",
    "    # and B is equal to (yl - yr) below lmidx and initially zero above.\n",
    "    B = zeros(x.shape)\n",
    "    B[:lmidx] = yl - yr\n",
    "    Bnew = B.copy()\n",
    "\n",
    "    it = 0\n",
    "    while it < maxit:\n",
    "        if DEBUG:\n",
    "            print(\"Shirley iteration: \", it)\n",
    "        # Calculate new k = (yl - yr) / (int_(xl)^(xr) J(x') - yr - B(x') dx')\n",
    "        ksum = 0.0\n",
    "        for i in range(lmidx, imax):\n",
    "            ksum += (x[i] - x[i + 1]) * 0.5 * (y[i] + y[i + 1]\n",
    "                                               - 2 * yr - B[i] - B[i + 1])\n",
    "        k = (yl - yr) / ksum\n",
    "        # Calculate new B\n",
    "        for i in range(lmidx, rmidx):\n",
    "            ysum = 0.0\n",
    "            for j in range(i, imax):\n",
    "                ysum += (x[j] - x[j + 1]) * 0.5 * (y[j] +\n",
    "                                                   y[j + 1] - 2 * yr - B[j] - B[j + 1])\n",
    "            Bnew[i] = k * ysum\n",
    "        # If Bnew is close to B, exit.\n",
    "        if norm(Bnew - B) < tol:\n",
    "            B = Bnew.copy()\n",
    "            break\n",
    "        else:\n",
    "            B = Bnew.copy()\n",
    "        it += 1\n",
    "\n",
    "    if it >= maxit:\n",
    "        print(\"specs.shirley_calculate: Max iterations exceeded before convergence.\")\n",
    "    if is_reversed:\n",
    "        return (yr + B)[::-1]\n",
    "    else:\n",
    "        return yr + B "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### plot functions #################### \n",
    "\n",
    "def Stgraf(x, y, st='o', xli=(400,610), xlab='BE (eV)', ylab='Intensidade ($10^2$ cps)'):\n",
    "    \"\"\" Funcao que plota o primeiro grafico, sem nenhum tratamento.\n",
    "    \"\"\" \n",
    "    plt.plot(x, y/100,st, markersize=6,linewidth=3, markeredgecolor='black', alpha=0.5)\n",
    "    plt.xlim(xli)\n",
    "    \n",
    "    plt.xlabel(xlab, fontsize=24)\n",
    "    plt.ylabel (ylab, fontsize=24)\n",
    "    plt.grid(True,color ='lightgray',linestyle='--',linewidth='1')\n",
    "    plt.tick_params('both', labelsize=20)\n",
    "    plt.savefig('stgraf_320eV.jpeg')\n",
    "    \n",
    "    return plt.show()\n",
    "#####\n",
    "\n",
    "def Segraf(x,y1,y2, xli=(400,610)):\n",
    "    \"\"\" Funcao que plota o segundo grafico, onde e mostrada a curva de background linear.\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.plot(x, y1)\n",
    "    plt.plot(x,y2)\n",
    "    plt.xlim(xli)\n",
    "    \n",
    "    return plt.show()\n",
    "#####    \n",
    "\n",
    "def Tgraf(x, y1, y2, sta='-k', stb='-r', xli=(400,610),xlab='BE (eV)', ylab='Intensidade ($10^2$ cps)'):\n",
    "    \"\"\" Funcao que plota o terceiro grafico, onde é mostrado os valores de Counts retirado o background linear junto com a \n",
    "    curva de background shirley.\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.plot(x,y1/100,sta,markersize=6,linewidth=3,markeredgecolor='black', alpha=0.5)\n",
    "    plt.plot(x,y2/100,stb)\n",
    "    plt.xlim(xli)\n",
    "\n",
    "    plt.xlabel(xlab, fontsize=24)\n",
    "    plt.ylabel (ylab, fontsize=24)\n",
    "    plt.grid(True,color ='lightgray',linestyle='--',linewidth='1')\n",
    "    plt.tick_params('both', labelsize=15)\n",
    "    plt.savefig('trgraf_320eV.jpeg')\n",
    "    \n",
    "    return plt.show()\n",
    "#####\n",
    "\n",
    "def Lgraf(x, y, st='-k', yli=-0.1, xli=(400,610), xlab='BE (eV)', ylab='Intensidade ($10^2$ cps)', titl='XPS data'):\n",
    "    \"\"\" Função que plota o ultimo grafico apos retirar todos os backgrounds    \n",
    "    \"\"\"    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.plot(x, y/100,st, markersize=6,linewidth=3, markerfacecolor='lightgray', markeredgecolor='black', alpha=0.5)\n",
    "\n",
    "    plt.ylim(yli)\n",
    "    plt.xlim(xli)\n",
    "\n",
    "    plt.xlabel(xlab, fontsize=20)\n",
    "    plt.ylabel (ylab, fontsize=20)\n",
    "    plt.title(titl, fontsize=18 )\n",
    "    plt.grid(True,color ='lightgray',linestyle='--',linewidth='1')\n",
    "    plt.tick_params('both', labelsize=15)\n",
    "    plt.savefig('lgraf_320eV.jpeg')\n",
    "    \n",
    "    return plt.show()\n",
    "#####\n",
    "\n",
    "def graf_phi(cy,dici,y='Ksi',st='-k'):\n",
    "    \"\"\" Funcao que plota um grafico de uma coluna de um dataframe presente em um dicionario em função da coluna theta\n",
    "    do mesmo dataframe, pra um vaolr fixo de phi (azimuths).\n",
    "    ###########\n",
    "    Parametros\n",
    "    ----------\n",
    "    cy : int-type\n",
    "        O numero do cycle (que se relaciona diretamente com o valor fixo de phi que se deseja plotar) presente no\n",
    "        dataframe que ira utilizar.\n",
    "    dici: dic-type\n",
    "        Um dicionario que contenha o dataframe de onde serao retirado os dados.\n",
    "    y: str-type, padrao 'Ksi'\n",
    "        O nome da coluna do dataframe que será utilizada no eixo das ordenadas.\n",
    "    st: str-type, padrao '-k'\n",
    "        O estilo do grafico a ser plotado.\n",
    "    \n",
    "    ###########\n",
    "    \"\"\"\n",
    "    \n",
    "    ex_phi=cy\n",
    "    z=list()\n",
    "    zz=list()\n",
    "    for key in dici:\n",
    "        #print(key)\n",
    "        data_index=dici[key][0]\n",
    "        data_index['Theta']=np.array(abs(data_index['Theta']))\n",
    "        data_index=data_index.reindex(columns=['Cycle','Phi','Curve', 'Theta', 'Area','Psi','Ksi', 'Log_area'])\n",
    "        data_index= data_index.sort_values(by=['Cycle', 'Phi'])\n",
    "        q=np.arange(len(data_index))\n",
    "        data_index[' ']=q\n",
    "        data_index=data_index.set_index(' ')\n",
    "\n",
    "        j=len(dici[key][0])\n",
    "        for row in range(j):\n",
    "            if data_index['Cycle'][row]==ex_phi:\n",
    "                z.append(data_index['Theta'][row])\n",
    "                zz.append(data_index[y][row])\n",
    "\n",
    "    z=np.array(z)\n",
    "    zz=np.array(zz)\n",
    "    data_graf=pd.DataFrame(z, columns=['Theta'])\n",
    "    data_graf[y]=zz\n",
    "    data_graf= data_graf.sort_values(by=['Theta'])\n",
    "    q=np.arange(len(data_graf))\n",
    "    data_graf[' ']=q\n",
    "    data_graf=data_graf.set_index(' ')\n",
    "    #print(data_graf)\n",
    "    z=data_graf['Theta']\n",
    "    zz=data_graf[y]\n",
    "    \n",
    "    l=len(z)\n",
    "    plt.plot(z,zz,st)\n",
    "    plt.xlim(z[0]-1, z[l-1]+1)\n",
    "    plt.xlabel('Theta (deg)', fontsize=15)\n",
    "    plt.ylabel(y, fontsize=16)\n",
    "    \n",
    "    return plt.show()\n",
    "#####\n",
    "\n",
    "def graf_theta(tli,cur,dici,b,y='Ksi',st='-k'):\n",
    "    \"\"\" Funcao que plota um grafico de uma coluna de um dataframe presente em um dicionario em função da coluna phi\n",
    "    do mesmo dataframe, pra um vaolr fixo de theta (polar).\n",
    "    ###########\n",
    "    Parametros\n",
    "    ----------\n",
    "    tli : int-type\n",
    "        O numero total de linhas presente no dataframe que ira utilizar (pode-se chegar a esse valor multiplicando a\n",
    "        quantidade de cycles pela quantidade de curves). Esse valor sera utilizado como intervalo para execucao do \n",
    "        loop for. Um intervalo, desde que valido, tambem e admtido:\n",
    "            { (inicio(opcional), fim, passo(opcional)), ex.: 1-(910); 2-(200,800); 3-(200,800,2) }\n",
    "    cur : int-type\n",
    "        O valor da curva (que se relaciona diretamente com o valor escolhido para fixar theta) presente no dataframe\n",
    "        que ira utilizar. Nao exceder a quantidade de curvas presentes por cycle. Ex.: cada cycle do dataframe possui\n",
    "            10 curves (os valore validos seriam de 0 a 9), o numero de curva 10, ou superior, nao sera aceito.\n",
    "    dici: dic-type\n",
    "        Um dicionario que contenha o dataframe de onde serao retirados os dados.\n",
    "    b : str-type\n",
    "        Keys do dicionario. Por padrao as keys sao os nomes dos arquivos de texo lidos pelo programa. Pode-se acessar\n",
    "        as keys de um dicionario com o comando <nome do dicionario>.keys(). Ex.: Arquivos2.keys()\n",
    "    y : str-type, padrao 'Ksi'\n",
    "        O nome da coluna do dataframe que será utilizada no eixo das ordenadas.\n",
    "    st : str-type, padrao '-k'\n",
    "        O estilo do grafico a ser plotado.\n",
    "    \n",
    "    ###########\n",
    "    \"\"\"\n",
    "    \n",
    "    ex_theta=cur\n",
    "    z=list()\n",
    "    zz=list()\n",
    "    for row in range(tli):\n",
    "        if dici[b][0]['Curve'][row]==ex_theta:\n",
    "            z.append(dici[b][0]['Phi'][row])\n",
    "            zz.append(dici[b][0][y][row])\n",
    "    z=np.array(z)\n",
    "    zz=np.array(zz)\n",
    "    #print(z)\n",
    "    \n",
    "    plt.plot(z,zz,st)\n",
    "    plt.xlim((z[0]-1, z[-1]+1))\n",
    "    plt.xlabel('Phi (deg)', fontsize=15)\n",
    "    plt.ylabel(y, fontsize=16)\n",
    "\n",
    "    return plt.show()\n",
    "#####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "## comando para medir o tempo de execução do programa. Exclusivo para o Jupyter notebook\n",
    "\n",
    "################################## funcao principal (main) ######################################\n",
    "\n",
    "arq= glob.glob('XPD_Cu_2_snapshot_th*.xy')   ## armazena os nomes dos arquivos a serem lidos na array 'arq', nessa forma\n",
    "                                             ## só funciona no jupyter, sendo que os arquivos a serem lidos devem estar\n",
    "                                             ## na mesma pasta deste script.\n",
    "        \n",
    "## No formato abaixo, ela funciona de forma geral, pois é especificado o endereço da pasta que contem os arquivos.                                             \n",
    "## arq= glob.glob('C:\\Users\\luiz.renato\\Google Drive\\Bolsa Verao 2018\\Jupyter\\Dados reais\\FG664_XPD_T*.xy')\n",
    "## print(arq)\n",
    "\n",
    "## declara dicionarios que serao usados para armazenar os dados ao fim do programa\n",
    "Arquivos1 = dict()\n",
    "\n",
    "\n",
    "## For para ler cada arquivo de dados \n",
    "for a in arq:\n",
    "    file_str= open(a,'r').read()\n",
    "    getelmt = re.split('Region: *', file_str)[1:]\n",
    "    ## separa os dados dos elementos diferentes presentes no arquivo\n",
    "    elmt1= getelmt[0]\n",
    "    print(a)\n",
    "    \n",
    "    ind=-1\n",
    "    newp=list()\n",
    "    newt=list()\n",
    "\n",
    "    ## For para ler os dados dos elementos ja separados\n",
    "    for i in [elmt1]:\n",
    "\n",
    "        ##coletando informacao do valor dos angulos\n",
    "        azimuths = re.findall('Parameter: \\\"azimuth \\[deg\\]\\\" = (-?[0-9]*)', i)\n",
    "#        #polars = re.findall('Parameter: \\\"polar \\[deg\\]\\\" = (-?[0-9]*)', i)\n",
    "        theta = int(a[20:22])*(-1)\n",
    "                \n",
    "        phi = np.array(azimuths).astype('int')\n",
    "#        #theta = np.array(polars).astype('int')\n",
    "        \n",
    "        ## Separando as informacoes dos dados em si\n",
    "        medidas = re.split('Cycle: [0-9]*, Curve: [0-9]*', i)[1:]\n",
    "        cycle_curve = re.findall('(Cycle: [0-9]*, Curve: [0-9]*)', i)\n",
    "        NonEO= re.findall('NonEnergyOrdinate: (-?[0-9.]*)',i)\n",
    "        \n",
    "        ## Declarando listas para armazenamento provisorio de dados\n",
    "        aaa=list()\n",
    "        aab=list()\n",
    "        aac=list()\n",
    "        aaf=list()\n",
    "        k=0\n",
    "        for cc,non,med in zip(cycle_curve,NonEO,medidas):\n",
    "            cycle = int(re.findall('Cycle: ([0-9]*)',cc)[0])\n",
    "            curve = int(re.findall('Curve: ([0-9]*)',cc)[0])\n",
    "            if curve==0:\n",
    "                ind+=1\n",
    "            ## Para aleitura desta coleção de arquivos especificamente este if permite quebrar em determinado ciclo a coleta\n",
    "            ## de dados do arquivo com o nome especificado abaixo\n",
    "            if a=='XPD_Cu_2_snapshot_th51.xy':\n",
    "                if cycle==61: \n",
    "                    break\n",
    "            if a == 'XPD_Cu_2_snapshot_th70.xy':\n",
    "                if cycle<=9:\n",
    "#                    print('ok')\n",
    "                    continue\n",
    "                elif curve<=1:\n",
    "                    continue\n",
    "                    \n",
    "            NEO = float(non) ## transforma para float os dados presentes em NonEO\n",
    "                      \n",
    "            nums = re.findall('(-?[0-9.]*  -?[0-9.]*)',med) ## Busca pelos dados na variavel 'med'\n",
    "#            print(nums)\n",
    "#            print(cycle, curve)\n",
    "            be = list()\n",
    "            counts = list()\n",
    "            \n",
    "            ## For para separar os dados em suas listas proprias\n",
    "            for n in nums:\n",
    "                try:\n",
    "                    be.append(float(n.split('  ')[0]))\n",
    "                    counts.append(float(n.split('  ')[1]))\n",
    "                except:\n",
    "                    break\n",
    "            ## armazenas os dados abaixo em uma unica lista\n",
    "            aaa.append([cycle, curve, NEO, be, counts])\n",
    "            newp.append(phi[ind])\n",
    "            newt.append(theta)\n",
    "#            print(be)\n",
    "#            print(counts)\n",
    "                \n",
    "            ## passa os dados de lista para uma array do numpy    \n",
    "            BE= np.array(be)\n",
    "            Counts= np.array(counts)\n",
    "#            print(type(BE), type(Counts))\n",
    "#            print(len(be),len(counts) )\n",
    "                \n",
    "            ## grafico inicial, sem tatamento algum dos dados\n",
    "#            Stgraf(BE, Counts,st='ok', xli=(BE[0]-0.5, BE[-1]+0.5)) \n",
    "#            input(\"Press Enter to continue...\")\n",
    "\n",
    "            ## Chama a funcao que retira o background linear\n",
    "#            Bline = linearBG(BE,Counts)\n",
    "#            print(len(Bline))\n",
    "\n",
    "            ## grafico que plota a linha de backgroud linear junto com os dados iniciais\n",
    "#            Segraf(BE, Bline, Counts, xli=(BE[0]-0.5, BE[-1]+0.5))\n",
    "#            input(\"Press Enter to continue...\")\n",
    "\n",
    "            ## subtracao do BG linear do counts\n",
    "#            LCounts = Counts-Bline\n",
    "\n",
    "            ## tira o backgroud shirley, neste caso direto dos dados e subtrai do counts\n",
    "            Bsh = shirley(BE,Counts, tol=1e-5, maxit=40)\n",
    "            SCounts = Counts - Bsh\n",
    "#            print(Bsh)\n",
    "\n",
    "            ## plota o grafico com a linha de BG shirley junto com os dados sem tratamento\n",
    "#            Tgraf=(BE, Counts, Bsh)\n",
    "#            input(\"Press Enter to continue...\")\n",
    "\n",
    "            ## Plota o grafico final, ja retirado o BG dos dados.\n",
    "#            Lgraf(BE, SCounts, xli=(BE[0]-0.5, BE[-1]+0.5))\n",
    "#            input(\"Press Enter to continue...\")\n",
    "            \n",
    "            #plota gráficos de cycles e curves específicos para um determinado arquivo\n",
    "#            if a=='XPD_Cu_2_snapshot_th13.xy':\n",
    "#                if curve==4:\n",
    "#                    if cycle==31:\n",
    "#                        Stgraf(BE, Counts,st='ok', xli=(BE[0]-0.5, BE[-1]+0.5))\n",
    "#                        Tgraf(BE, Counts, Bsh, sta='-k', stb='-r', xli=(BE[0]+2, BE[-1]-2),xlab='BE (eV)', ylab='Intensidade ($10^2$ cps)')\n",
    "#                        Lgraf(BE, SCounts,yli=-0.1, xli=(BE[0]-0.5, BE[-1]+0.5))\n",
    "\n",
    "\n",
    "            ## integra os dados para calcular a area sob a cuva\n",
    "            area = integrate.simps(SCounts,dx=0.05)\n",
    "#            aab.append(Bline)\n",
    "            aac.append(Bsh)\n",
    "            aaf.append(area)\n",
    "            #print(area)              \n",
    "               \n",
    "        ## transforma as listas em arrays do numpy para gerar dataframes com os dados     \n",
    "        aa= np.array(aaa, dtype=object)\n",
    "        newp=np.array(newp)\n",
    "        newt=np.array(newt)\n",
    "        \n",
    "               \n",
    "        ######### Data Frame com  informações separadas em colunas e separadas por arquivo de dados ###########\n",
    "        if i==elmt1:\n",
    "            Inf1 = pd.DataFrame(aa, columns=['Cycle', 'Curve', 'NonEnerOrd', 'BE', 'Counts'])\n",
    "            Inf1['Phi'] = newp\n",
    "            Inf1['Theta'] = newt\n",
    "            Inf1= Inf1.reindex(columns=['Cycle', 'Curve', 'NonEnerOrd', 'Phi', 'Theta', 'BE', 'Counts'])\n",
    "#            Inf1['BGL'] = aab\n",
    "            Inf1['BSh'] = aac\n",
    "            Inf1['Area'] = aaf\n",
    "\n",
    "        \n",
    "    ### Dicionario com informacoes de todos os arquivos\n",
    "    ## A chave para selecionar uma colecao de dados e o nome completo do arquivo lido\n",
    "    ## na duvida utilize o comando Arquivos1.keys()\n",
    "    Arquivos1[a]=[Inf1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "### For que organiza os dados em um novo dataframe para a plotagem de graficos mais refinados\n",
    "## Dicionario para armazenar os dados ao final do programa\n",
    "Arquivos2 = dict()\n",
    "\n",
    "## Tratamento especifico para esse arquivo de dados\n",
    "for key in Arquivos1:\n",
    "    if key=='XPD_Cu_2_snapshot_th51_2.xy':\n",
    "        Arquivos1[key][0]['Cycle']=np.array(Arquivos1[key][0]['Cycle']+60)\n",
    "    print(key)\n",
    "    Data0=Arquivos1[key][0]\n",
    "    Data1=Data0.loc[:, ['Curve','Cycle','Phi','Area']]\n",
    "    Data1['Theta']=Data0['Theta'] + Data0['NonEnerOrd']\n",
    "    Data1=Data1.reindex(columns=['Curve', 'Theta','Cycle','Phi', 'Area'])\n",
    "    Data2= Data1.sort_values(by=['Curve', 'Theta'])\n",
    "    q=np.arange(len(Data2))\n",
    "    Data2[' ']=q\n",
    "    Data2=Data2.set_index(' ')\n",
    "        \n",
    "    ## tira a media dos valores da area para realizar a normalizacao dos dados\n",
    "    soma=0\n",
    "    N=0\n",
    "    nor=list()\n",
    "    l_val2=list()\n",
    "    angle2=list()\n",
    "    interval=range(len(Data2))\n",
    "    for lin in interval:\n",
    "        if lin == 0:\n",
    "            angle2.append(Data2['Theta'][lin])\n",
    "            soma=soma+Data2['Area'][lin]\n",
    "            nor.append(Data2['Area'][lin])\n",
    "            N+=1\n",
    "        elif lin==interval[-1]:\n",
    "            soma=soma+Data2['Area'][lin]\n",
    "            nor.append(Data2['Area'][lin])\n",
    "            N+=1\n",
    "            pico=np.amax(nor)\n",
    "            vale=np.amin(nor)\n",
    "            l_val2.append([soma,N,pico,vale])\n",
    "        elif Data2['Theta'][lin] == Data2['Theta'][lin-1]:\n",
    "            soma=soma+Data2['Area'][lin]\n",
    "            nor.append(Data2['Area'][lin])\n",
    "            N+=1\n",
    "        elif Data2['Theta'][lin] == Data2['Theta'][lin+1]:\n",
    "            angle2.append(Data2['Theta'][lin])\n",
    "            pico=np.amax(nor)\n",
    "            vale=np.amin(nor)\n",
    "            l_val2.append([soma,N,pico,vale])\n",
    "            N=0\n",
    "            soma=0\n",
    "            nor=list()\n",
    "            soma=soma+Data2['Area'][lin]\n",
    "            nor.append(Data2['Area'][lin])\n",
    "            N+=1\n",
    "#        print(soma)\n",
    "\n",
    "    interval=range(len(l_val2))\n",
    "    media2=list()\n",
    "    for v in interval:\n",
    "        M = l_val2[v][0]/l_val2[v][1]\n",
    "#        print(M)\n",
    "        media2.append(M)\n",
    "    Media2=np.array([media2, angle2])\n",
    "        \n",
    "    ## realisa a normalizacao dos dados pela média dos valores para um mesmo theta e armazena no dataframe\n",
    "    val=0\n",
    "    norma=list()\n",
    "    interval=range(len(Data2))\n",
    "    for lin in interval:\n",
    "        if Data2['Theta'][lin]==Media2[1][val]:\n",
    "            psi= (Data2['Area'][lin] - Media2[0][val])/Media2[0][val]\n",
    "            norma.append(psi)\n",
    "            \n",
    "            if Data2['Theta'][lin] != Data2['Theta'][interval[-1]] and Data2['Theta'][lin] != Data2['Theta'][lin+1]:\n",
    "                val+=1\n",
    "        else:\n",
    "            print('Erro ao normalisar')\n",
    "            print(lin, 'err', val)\n",
    "    Psi=np.array(norma)\n",
    "    Data2['Psi']=Psi\n",
    "    \n",
    "    ## realisa a normalizacao dos dados com base nos valores maximos e minimos para um mesmo theta e armazena no dataframe\n",
    "    val=0\n",
    "    norma=list()\n",
    "    interval=range(len(Data2))\n",
    "    for lin in interval:\n",
    "        if Data2['Theta'][lin]==Media2[1][val]:\n",
    "            ksi= (Data2['Area'][lin] - l_val2[val][3])/(l_val2[val][2]-l_val2[val][3])\n",
    "            norma.append(ksi)\n",
    "            \n",
    "            if Data2['Theta'][lin] != Data2['Theta'][interval[-1]] and Data2['Theta'][lin] != Data2['Theta'][lin+1]:\n",
    "                    val+=1\n",
    "        else:\n",
    "            print('Erro ao normalisar')\n",
    "            print(lin, 'err', val)\n",
    "    Ksi=np.array(norma)\n",
    "    Data2['Ksi']=Ksi\n",
    "    \n",
    "    data_op= np.array(Data2['Area'])\n",
    "    data_op= np.log10(data_op)\n",
    "    Data2['Log_area']=data_op    \n",
    "     \n",
    "            \n",
    "    Arquivos2[key]=[Data2, Media2]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Utilizacao das funcoes que plotam graficos em relacao a phi ou a theta\n",
    "#graf_phi(30,Arquivos2,y='Area',st='-ok')\n",
    "#graf_theta(910,4,Arquivos2,'XPD_Cu_2_snapshot_th13.xy',y='Ksi',st='-k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## comando para imprimir todo o dataframe do arquivo especificado\n",
    "\n",
    "#b='XPD_Cu_2_snapshot_th32.xy'\n",
    "#j=len(Arquivos2[b][0])\n",
    "#print('Curve','\\t','Theta','\\t\\t','Cycle','\\t','Phi','\\t\\t','Area','\\t\\t','Psi','\\t\\t','Ksi')\n",
    "#for row in range(j):\n",
    "#    print(Arquivos2[b][0]['Curve'][row],'\\t',Arquivos2[b][0]['Theta'][row],'\\t',Arquivos2[b][0]['Cycle'][row],'\\t',\n",
    "#          Arquivos2[b][0]['Phi'][row],'\\t',Arquivos2[b][0]['Area'][row],'\\t',Arquivos2[b][0]['Psi'][row],'\\t',\n",
    "#          Arquivos2[b][0]['Ksi'][row])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## tratamento dos dados presente nos dicionarios para a plotagem de difratogramas\n",
    "## leitura do dicionario\n",
    "Data01=Arquivos2['XPD_Cu_2_snapshot_th13.xy'][0]\n",
    "Data02=Arquivos2['XPD_Cu_2_snapshot_th32.xy'][0]\n",
    "Data03=Arquivos2['XPD_Cu_2_snapshot_th51.xy'][0]\n",
    "Data04=Arquivos2['XPD_Cu_2_snapshot_th51_2.xy'][0]\n",
    "Data05=Arquivos2['XPD_Cu_2_snapshot_th70.xy'][0]\n",
    "\n",
    "## transforma os dados em uma array do numpy\n",
    "phi_data01 = np.array(Data01['Phi'])\n",
    "theta_data01 = np.array(Data01['Theta'])\n",
    "#area_data01 = np.array(Data01['Area'])\n",
    "#area_data01 = np.array(Data01['Psi'])\n",
    "area_data01 = np.array(Data01['Ksi'])\n",
    "#area_data01 = np.array(Data01['Log_area'])\n",
    "\n",
    "phi_data02 = np.array(Data02['Phi'])\n",
    "theta_data02 = np.array(Data02['Theta'])\n",
    "#area_data02 = np.array(Data02['Area'])\n",
    "#area_data02 = np.array(Data02['Psi'])\n",
    "area_data02 = np.array(Data02['Ksi'])\n",
    "#area_data02 = np.array(Data02['Log_area'])\n",
    "\n",
    "phi_data03 = np.array(Data03['Phi'])\n",
    "theta_data03 = np.array(Data03['Theta'])\n",
    "#area_data03 = np.array(Data03['Area'])\n",
    "#area_data03 = np.array(Data03['Psi'])\n",
    "area_data03 = np.array(Data03['Ksi'])\n",
    "#area_data03 = np.array(Data03['Log_area'])\n",
    "\n",
    "phi_data04 = np.array(Data04['Phi'])\n",
    "theta_data04 = np.array(Data04['Theta'])\n",
    "#area_data04 = np.array(Data04['Area'])\n",
    "#area_data04 = np.array(Data04['Psi'])\n",
    "area_data04 = np.array(Data04['Ksi'])\n",
    "#area_data04 = np.array(Data04['Log_area'])\n",
    "\n",
    "phi_data05 = np.array(Data05['Phi'])\n",
    "theta_data05 = np.array(Data05['Theta'])\n",
    "#area_data05 = np.array(Data05['Area'])\n",
    "#area_data05 = np.array(Data05['Psi'])\n",
    "area_data05 = np.array(Data05['Ksi'])\n",
    "#area_data05 = np.array(Data05['Log_area'])\n",
    "\n",
    "## reorganiza o modo como os dados sao apresentados utilizando o reshape\n",
    "phi_data01=np.reshape(phi_data01, (10,91))\n",
    "theta_data01=np.reshape(theta_data01, (10,91))\n",
    "area_data01=np.reshape(area_data01, (10,91))\n",
    "\n",
    "phi_data02=np.reshape(phi_data02, (10,91))\n",
    "theta_data02=np.reshape(theta_data02, (10,91))\n",
    "area_data02=np.reshape(area_data02, (10,91))\n",
    "\n",
    "phi_data03=np.reshape(phi_data03, (10,61))\n",
    "theta_data03=np.reshape(theta_data03, (10,61))\n",
    "area_data03=np.reshape(area_data03, (10,61))\n",
    "\n",
    "phi_data04=np.reshape(phi_data04, (10,31))\n",
    "theta_data04=np.reshape(theta_data04, (10,31))\n",
    "area_data04=np.reshape(area_data04, (10,31))\n",
    "\n",
    "phi_data05=np.reshape(phi_data05, (8,81))\n",
    "theta_data05=np.reshape(theta_data05, (8,81))\n",
    "area_data05=np.reshape(area_data05, (8,81))\n",
    "\n",
    "## Plotagem do grafico em forma de \"pizza\"\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = plt.subplot(111, projection='polar')\n",
    "\n",
    "ma=1.1  ## vallor maximo para a escala de cor\n",
    "mi=0.2  ## valor minimo para a escala de cor\n",
    "xpd01= ax.contourf(np.radians(phi_data01), np.abs(theta_data01),area_data01, 100, vmin=mi, vmax=ma, cmap=cm.gray)\n",
    "xpd02= ax.contourf(np.radians(phi_data02), np.abs(theta_data02),area_data02, 100, vmin=mi, vmax=ma, cmap=cm.gray)\n",
    "xpd03 = ax.contourf(np.radians(phi_data03), np.abs(theta_data03),area_data03, 100, vmin=mi, vmax=ma, cmap=cm.gray)\n",
    "xpd04 = ax.contourf(np.radians(phi_data04), np.abs(theta_data04),area_data04, 100, vmin=mi, vmax=ma, cmap=cm.gray)\n",
    "xpd05 = ax.contourf(np.radians(phi_data05), np.abs(theta_data05),area_data05, 100, vmin=mi, vmax=ma, cmap=cm.gray)\n",
    "\n",
    "ax.set_yticklabels([]) ## remove os valores da coordenada radial\n",
    "#ax.set_xticklabels([])\n",
    "ax.set_rmax(84) ## define valor maximo da coordenada radial\n",
    "ax.set_rmin(0) ## define valor minimo da coordenada radia\n",
    "ax.grid(True); ## remove o grid\n",
    "#ax.set_title('a) Experimento', fontsize=24) ## Insere o título do grafico\n",
    "#fig.colorbar(xpd01)  ##\n",
    "#fig.colorbar(xpd02)  ##\n",
    "#fig.colorbar(xpd03)  ## Mostra a barra da escala de cores do grafico\n",
    "#fig.colorbar(xpd04)  ##\n",
    "#fig.colorbar(xpd05)  ##\n",
    "\n",
    "#plt.savefig('XPD_Cu_2_snapshot_theta_ksinorm.png')  ## Comando para salvar a figura\n",
    "plt.show()\n",
    "#input(\"Press enter to continue...\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graf_phi(49,Arquivos2,y='Ksi',st='--k')\n",
    "#graf_phi(10,Arquivos2,y='Ksi',st='--k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Sequencia para gerar o difratograma unindo todos os dados em um unico arquivo\n",
    "\n",
    "Data0=Arquivos2['XPD_Cu_2_snapshot_th13.xy'][0]\n",
    "Data00=Arquivos2['XPD_Cu_2_snapshot_th32.xy'][0]\n",
    "Data000=Arquivos2['XPD_Cu_2_snapshot_th51.xy'][0]\n",
    "Data0000=Arquivos2['XPD_Cu_2_snapshot_th51_2.xy'][0]\n",
    "Data00000=Arquivos2['XPD_Cu_2_snapshot_th70.xy'][0]\n",
    "\n",
    "\n",
    "phi_data0 = np.array(Data0['Phi']+60)\n",
    "theta_data0 = np.array(abs(Data0['Theta']))\n",
    "#area_data0 = np.array(Data0['Area'])\n",
    "#area_data0 = np.array(Data0['Psi'])\n",
    "area_data0 = np.array(Data0['Ksi'])\n",
    "#area_data0 = np.array(Data0['Log_area'])\n",
    "curve_data0 = np.array(Data0['Curve'])\n",
    "\n",
    "phi_data00 = np.array(Data00['Phi']+60)\n",
    "theta_data00 = np.array(abs(Data00['Theta']))\n",
    "#area_data00 = np.array(Data00['Area'])\n",
    "#area_data00 = np.array(Data00['Psi'])\n",
    "area_data00 = np.array(Data00['Ksi'])\n",
    "#area_data00 = np.array(Data00['Log_area'])\n",
    "curve_data00 = np.array(Data00['Curve']+10)\n",
    "\n",
    "phi_data000 = np.array(Data000['Phi']+60)\n",
    "theta_data000 = np.array(abs(Data000['Theta']))\n",
    "#area_data000 = np.array(Data000['Area'])\n",
    "#area_data000 = np.array(Data000['Psi'])\n",
    "area_data000 = np.array(Data000['Ksi'])\n",
    "#area_data000 = np.array(Data000['Log_area'])\n",
    "curve_data000 = np.array(Data000['Curve']+20)\n",
    "\n",
    "phi_data0000 = np.array(Data0000['Phi']+60)\n",
    "theta_data0000 = np.array(abs(Data0000['Theta']))\n",
    "#area_data0000 = np.array(Data0000['Area'])\n",
    "#area_data0000 = np.array(Data0000['Psi'])\n",
    "area_data0000 = np.array(Data0000['Ksi'])\n",
    "#area_data0000 = np.array(Data0000['Log_area'])\n",
    "curve_data0000 = np.array(Data0000['Curve']+20)\n",
    "\n",
    "phi_data00000 = np.array(Data00000['Phi']+60)\n",
    "theta_data00000 = np.array(abs(Data00000['Theta']))\n",
    "#area_data00000 = np.array(Data00000['Area'])\n",
    "#area_data00000 = np.array(Data00000['Psi'])\n",
    "area_data00000 = np.array(Data00000['Ksi'])\n",
    "#area_data00000 = np.array(Data00000['Log_area'])\n",
    "curve_data00000 = np.array(Data00000['Curve']+30)\n",
    "\n",
    "#################################################\n",
    "## Para essa sequncia de arquivos especificamente, ha a necessidade de unir dpois desses arquivos, \n",
    "## pois um completa o outro. A sequencia esta abaixo.\n",
    "phi_data000=np.reshape(phi_data000, (10,60))\n",
    "theta_data000=np.reshape(theta_data000, (10,60))\n",
    "area_data000=np.reshape(area_data000, (10,60))\n",
    "curve_data000 = np.reshape(curve_data000, (10,60))\n",
    "phi_data0000=np.reshape(phi_data0000, (10,31))\n",
    "theta_data0000=np.reshape(theta_data0000, (10,31))\n",
    "area_data0000=np.reshape(area_data0000, (10,31))\n",
    "curve_data0000 = np.reshape(curve_data0000, (10,31))\n",
    "\n",
    "phi= np.concatenate((phi_data000, phi_data0000), axis=1)\n",
    "theta= np.concatenate((theta_data000, theta_data0000), axis=1)\n",
    "area= np.concatenate((area_data000, area_data0000), axis=1)\n",
    "curve= np.concatenate((curve_data000, curve_data0000), axis=1)\n",
    "\n",
    "phi0= np.reshape(phi, (910))\n",
    "theta0= np.reshape(theta, (910))\n",
    "area0= np.reshape(area, (910))\n",
    "curve0= np.reshape(curve, (910))\n",
    "\n",
    "####################################################\n",
    "## Concatenando os dados em um unico array, separados, e claro, por tipo de dado\n",
    "phi_data = np.concatenate((phi_data0,phi_data00,phi0), axis=0)\n",
    "theta_data = np.concatenate((theta_data0,theta_data00,theta0), axis=0)\n",
    "area_data = np.concatenate((area_data0, area_data00, area0), axis=0)\n",
    "curve_data = np.concatenate((curve_data0, curve_data00, curve0), axis=0)\n",
    "\n",
    "Data_org = pd.DataFrame(curve_data, columns=['Curve'])\n",
    "Data_org['Theta']=theta_data\n",
    "Data_org['Phi']=phi_data\n",
    "Data_org['Area']=area_data\n",
    "Data_org= Data_org.sort_values(by=['Theta', 'Phi'], ascending=True)\n",
    "q=np.arange(len(Data_org))\n",
    "Data_org[' ']=q\n",
    "Data_org=Data_org.set_index(' ')\n",
    "\n",
    "phi_data = np.array(Data_org['Phi'])\n",
    "theta_data = np.array(Data_org['Theta'])\n",
    "area_data = np.array(Data_org['Area'])\n",
    "\n",
    "##################\n",
    "## Reshape para a formacao do difratograma\n",
    "phi_data=np.reshape(phi_data, (30,91))\n",
    "theta_data=np.reshape(theta_data, (30,91))\n",
    "area_data=np.reshape(area_data, (30,91))\n",
    "\n",
    "## Sequencia para a plotagem do difratograma  \n",
    "fig = plt.figure(figsize=(15,15))\n",
    "ax = plt.subplot(111, projection='polar')\n",
    "xpd=ax.contourf(np.radians(phi_data), np.abs(theta_data),area_data, 100, vmin=0, vmax=1, cmap=cm.gray)\n",
    "\n",
    "ax.set_yticklabels([])# remove os valores da coordenada radial\n",
    "#ax.set_xticklabels([])\n",
    "ax.set_rmax(90) # define valor maximo da coordenada radial\n",
    "ax.set_rmin(0) #define valor minimo da coordenada radia\n",
    "ax.grid(True); #remove o grid\n",
    "fig.colorbar(xpd)\n",
    "\n",
    "#plt.savefig('XPD_Cu_2_snapshot_phi.jpg')  ## Salvar o difratograma em figura\n",
    "plt.show()\n",
    "#input(\"Press enter to continue...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
